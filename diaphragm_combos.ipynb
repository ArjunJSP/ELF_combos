{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOxNzPs6Vf11XgfjhVd1vTj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArjunJSP/ELF_combos/blob/eccentricity-combos/diaphragm_combos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wONJBvka7tgv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "from google.colab import data_table\n",
        "import itertools\n",
        "from itertools import permutations\n",
        "from itertools import accumulate\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Navigate to a specific folder in your Google Drive\n",
        "%cd /content/drive/My Drive/mountlocation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvmL57c5JPM9",
        "outputId": "d815d360-a750-4317-cad3-4c4feafd5d07"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/mountlocation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Input Files for Editing"
      ],
      "metadata": {
        "id": "aYw8lge_-q1W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#e2k File to write-to (currently not using)\n",
        "e2k_file = 'RSFH_PODIUM_V11.2.4.e2k'\n",
        "\n",
        "#ETABS Excel output of story forces for RSX-ELF, RSY-ELF, and 00_SEISMASS, as well as Mass Summary by Story Table\n",
        "file_path = \"StoryForces_PODIUM_V11.2.4.xlsx\""
      ],
      "metadata": {
        "id": "rDSAplQ0-qbc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Story Forces and Static Load Case scale factors\n",
        "\n",
        "Data defined in this section include:\n",
        "*   pv_storyshears_X\n",
        "*   pv_storyshears_Y\n",
        "*   pv_seismass\n",
        "*   base_shear_coeff_VX\n",
        "*   base_shear_coeff_VY\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "e_BZ4c7xICXv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Seismic Factors for Fpx calculation:\n",
        "Sds = 1.17  #updated Sds\n",
        "Ie = 1.5"
      ],
      "metadata": {
        "id": "LixUxsXGuSpb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#######evaluate units more carefully for the excel sheet - or make sure they are exported to access using the right units!\n",
        "# Read the first two rows to get headers and sub-headers\n",
        "headers = pd.read_excel(file_path, sheet_name=\"Story Forces\", header=[1])\n",
        "\n",
        "# Read the actual data, skipping the first two rows used for headers\n",
        "df_storyforces = pd.read_excel(file_path, sheet_name=\"Story Forces\", skiprows=[0, 1,2])\n",
        "\n",
        "# Set the MultiIndex columns\n",
        "df_storyforces.columns = headers.columns"
      ],
      "metadata": {
        "id": "Nfpuz68aIIZW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#######evaluate units more carefully for the excel sheet - or make sure they are exported to access using the right units!\n",
        "# Read the first two rows to get headers and sub-headers\n",
        "headers = pd.read_excel(file_path, sheet_name=\"Mass Summary by Story\", header=[1])\n",
        "\n",
        "# Read the actual data, skipping the first two rows used for headers\n",
        "df_masssummary = pd.read_excel(file_path, sheet_name=\"Mass Summary by Story\", skiprows=[0, 2])\n",
        "\n",
        "df_masssummary['P'] = df_masssummary['UX']*32.2/1000 #multiply by gravity and convert to kips (units must be lb-s^2/ft for mass)\n",
        "df_masssummary['P_Total'] = df_masssummary['P'].cumsum(axis = 0, skipna = True) #cumulative mass added up along building\n",
        "dropindex = df_masssummary.loc[df_masssummary['Story'] == 'L00'].index[0]\n",
        "df_masssummary = df_masssummary.drop(dropindex, axis=0)"
      ],
      "metadata": {
        "id": "pLM3Fr7_FSpw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#required inputs:\n",
        "num_levels = len(df_storyforces['Story'].drop_duplicates())"
      ],
      "metadata": {
        "id": "ogGyPN3t_dY4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#collapse story force output into useable dataframes\n",
        "relevant_cols = ['Story','Output Case','Step Type','Location','VX','VY']\n",
        "pv_storyshears_X = df_storyforces[relevant_cols]\n",
        "pv_storyshears_X = pv_storyshears_X[pv_storyshears_X['Location'].isin(['Bottom'])]\n",
        "pv_storyshears_X = pv_storyshears_X[pv_storyshears_X['Step Type'].isin(['Max'])]\n",
        "pv_storyshears_X = pv_storyshears_X[pv_storyshears_X['Output Case'].isin(['RSX-STR (ELF)'])]\n",
        "\n",
        "pv_storyshears_Y = df_storyforces[relevant_cols]\n",
        "pv_storyshears_Y = pv_storyshears_Y[pv_storyshears_Y['Location'].isin(['Bottom'])]\n",
        "pv_storyshears_Y = pv_storyshears_Y[pv_storyshears_Y['Step Type'].isin(['Max'])]\n",
        "pv_storyshears_Y = pv_storyshears_Y[pv_storyshears_Y['Output Case'].isin(['RSY-STR (ELF)'])]\n",
        "\n",
        "relevant_cols = ['Story','Output Case','Location','P']\n",
        "pv_seismass = df_storyforces[relevant_cols]\n",
        "pv_seismass = pv_seismass[pv_seismass['Location'].isin(['Bottom'])]\n",
        "pv_seismass = pv_seismass[pv_seismass['Output Case'].isin(['00_SEISMIC MASS'])]"
      ],
      "metadata": {
        "id": "tn8FVapiIOkk"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #Calculate the static base shear coefficients for X\n",
        "# base_shear_coeff_VX = pv_storyshears_X['Story'].reset_index(drop=True).to_frame()\n",
        "# x_coeff = ( pv_storyshears_X['VX'].reset_index(drop=True)-pv_storyshears_X['VX'].shift(1).fillna(0).reset_index(drop=True) ) / ( pv_seismass['P'].reset_index(drop=True)-pv_seismass['P'].shift(1).fillna(0).reset_index(drop=True) )\n",
        "# x_coeff = x_coeff.rename(\"Coeff\").to_frame()\n",
        "# base_shear_coeff_VX = base_shear_coeff_VX.merge(x_coeff, left_index=True, right_index=True)\n",
        "\n",
        "# #Calculate the static base shear coefficients for Y\n",
        "# base_shear_coeff_VY = pv_storyshears_Y['Story'].reset_index(drop=True).to_frame()\n",
        "# y_coeff = ( pv_storyshears_Y['VY'].reset_index(drop=True)-pv_storyshears_Y['VY'].shift(1).fillna(0).reset_index(drop=True) ) / ( pv_seismass['P'].reset_index(drop=True)-pv_seismass['P'].shift(1).fillna(0).reset_index(drop=True) )\n",
        "# y_coeff = y_coeff.rename(\"Coeff\").to_frame()\n",
        "# base_shear_coeff_VY = base_shear_coeff_VY.merge(y_coeff, left_index=True, right_index=True)\n"
      ],
      "metadata": {
        "id": "3rjKgdzwuRZm"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate the static base shear coefficients for X\n",
        "base_shear_coeff_VX = pv_storyshears_X['Story'].reset_index(drop=True).to_frame()\n",
        "x_coeff = ( pv_storyshears_X['VX'].reset_index(drop=True)-pv_storyshears_X['VX'].shift(1).fillna(0).reset_index(drop=True) ) / (df_masssummary['P'])\n",
        "x_coeff = x_coeff.rename(\"Coeff\").to_frame()\n",
        "base_shear_coeff_VX = base_shear_coeff_VX.merge(x_coeff, left_index=True, right_index=True)\n",
        "\n",
        "#Calculate the static base shear coefficients for Y\n",
        "base_shear_coeff_VY = pv_storyshears_Y['Story'].reset_index(drop=True).to_frame()\n",
        "y_coeff = ( pv_storyshears_Y['VY'].reset_index(drop=True)-pv_storyshears_Y['VY'].shift(1).fillna(0).reset_index(drop=True) ) /  (df_masssummary['P'])\n",
        "y_coeff = y_coeff.rename(\"Coeff\").to_frame()\n",
        "base_shear_coeff_VY = base_shear_coeff_VY.merge(y_coeff, left_index=True, right_index=True)"
      ],
      "metadata": {
        "id": "_XrbrcyHJ8mU"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Permutation Parameters\n",
        "Generate all permutations for load combination based on the following parameters:\n",
        "- direction (X,Y)\n",
        "- level\n",
        "- eccentricity (P,N)\n"
      ],
      "metadata": {
        "id": "dvEpzbse9wsv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#function create parameter array for level names\n",
        "def create_l_array(n):\n",
        "    \"\"\"\n",
        "    Generate an array of text elements with the letter 'L' concatenated with numbers from 01 to n.\n",
        "    Adds a leading zero for numbers less than 10.\n",
        "\n",
        "    :param n: Length of the array.\n",
        "    :return: List of strings in the format 'L01', 'L02', ..., 'Ln'.\n",
        "    \"\"\"\n",
        "    return [f\"L{str(i).zfill(2)}\" for i in range(n, 0, -1)]\n"
      ],
      "metadata": {
        "id": "HO6ZwoXb-j56"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#axis parameters\n",
        "param_axis = ['X','Y']\n",
        "\n",
        "#level parameters\n",
        "param_level = create_l_array(num_levels)\n",
        "\n",
        "#direction parameters\n",
        "param_direction = ['P','N']\n",
        "\n",
        "#eccentricity parameters\n",
        "param_ecc = ['P','N']\n",
        "ecc_percent = 0.05"
      ],
      "metadata": {
        "id": "Flh1-__K90i4"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function to create a list of permutations\n",
        "def generate_permutations(*criteria):\n",
        "    \"\"\"\n",
        "    Generate all possible permutations from multiple criteria lists.\n",
        "\n",
        "    :param criteria: Variable number of lists containing elements for permutation.\n",
        "    :return: List of tuples representing all possible permutations.\n",
        "    \"\"\"\n",
        "    return list(itertools.product(*criteria))"
      ],
      "metadata": {
        "id": "s4jjCFfX7_mt"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#permutations to compute:\n",
        "# 0: axis (X,Y)\n",
        "# 1: direction (positive, negative)\n",
        "# 2: eccentricity (positive, negative)\n",
        "# 3: level\n",
        "permutations = generate_permutations(param_axis, param_direction, param_ecc, param_level)\n",
        "n = len(permutations)"
      ],
      "metadata": {
        "id": "M9cQ8xnM_KCp"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculate Fpx Factors\n",
        "\n",
        "\n",
        "*   Fpx_SF = table of scale factors for each floor, for each direction\n",
        "\n"
      ],
      "metadata": {
        "id": "-Dg_XbFSgT3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Fpx calcualation based on ASCE 7-16 12.10.1.1: Diaphragm Design Forces (RE-WRITE USING MASS SOURCE)\n",
        "\n",
        "Wpx = df_masssummary['P']\n",
        "Fx_X = (pv_storyshears_X.VX - pv_storyshears_X.VX.shift(1).fillna(0.0)).reset_index(drop=True)\n",
        "Fx_Y = (pv_storyshears_Y.VY - pv_storyshears_Y.VY.shift(1).fillna(0.0)).reset_index(drop=True)\n",
        "\n",
        "Wi = df_masssummary['P_Total']\n",
        "Fi_x = pv_storyshears_X.VX.reset_index(drop=True)\n",
        "Fi_y = pv_storyshears_Y.VY.reset_index(drop=True)\n",
        "\n",
        "Fpx_X = [None] * num_levels\n",
        "Fpx_Y = [None] * num_levels\n",
        "\n",
        "for i in range(num_levels):\n",
        "  Fpx_X[i] = Fi_x[i]/Wi[i]*Wpx[i]       # 12.10-1\n",
        "  if Fpx_X[i] < 0.2*Sds*Ie*Wpx[i]:\n",
        "    Fpx_X[i] = 0.2*Sds*Ie*Wpx[i]        # 12.10-2\n",
        "  if Fpx_X[i] > 0.4*Sds*Ie*Wpx[i]:\n",
        "    Fpx_X[i] = 0.4*Sds*Ie*Wpx[i]        # 12.10-3\n",
        "\n",
        "for i in range(num_levels):\n",
        "  Fpx_Y[i] = Fi_y[i]/Wi[i]*Wpx[i]       # 12.10-1\n",
        "  if Fpx_Y[i] < 0.2*Sds*Ie*Wpx[i]:\n",
        "    Fpx_Y[i] = 0.2*Sds*Ie*Wpx[i]        # 12.10-2\n",
        "  if Fpx_Y[i] > 0.4*Sds*Ie*Wpx[i]:\n",
        "    Fpx_Y[i] = 0.4*Sds*Ie*Wpx[i]        # 12.10-3\n",
        "\n",
        "#Story Scale Factor coefficient\n",
        "Fpx_X_SF = (Fpx_X / Fx_X).round(2)\n",
        "Fpx_Y_SF = (Fpx_Y / Fx_Y).round(2)\n",
        "\n",
        "Fpx_SF = pd.DataFrame([Fpx_X_SF,Fpx_Y_SF]) # .rename(columns=param_level)\n",
        "Fpx_SF.columns = param_level\n",
        "Fpx_SF.index = ['X','Y']"
      ],
      "metadata": {
        "id": "JKjoBPQagWZy"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Generate Load Patterns\n",
        "\n",
        "*   pattern_array = names for all of the required load patterns, based on an individual pattern for each load permutation\n",
        "*   load_pattern_array = load_pattern_array1 + load_pattern_array2, where both are the component lines for the total line section that is the load pattern array\n",
        "\n"
      ],
      "metadata": {
        "id": "sRilnQvZCVyx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#first line in load pattern definitions\n",
        "\n",
        "pattern_array = [None] * n\n",
        "load_pattern_array1 = [None] * n\n",
        "for i in range(n):\n",
        "  pattern_array[i] = ' \"ELF-EQ'+ permutations[i][0] + permutations[i][1] + \"-\" + permutations[i][2] + \"-\" + permutations[i][3] + '\"'\n",
        "  load_pattern_array1[i] = \"  LOADPATTERN\" + pattern_array[i] + '  TYPE  \"Seismic\"  SELFWEIGHT  0'"
      ],
      "metadata": {
        "id": "Ygcms-dKH05U"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#second line in load pattern definitions\n",
        "\n",
        "## create a list of length 'n' to define positive (+) or negative (-) eccentricity\n",
        "ecc_array = [None] * n\n",
        "for i in range(n):\n",
        "  if permutations[i][2] == \"P\":\n",
        "    ecc_array[i] = 'DIR \"' + permutations[i][0] + '+ECC\"  ECC ' + str(ecc_percent)\n",
        "  else:\n",
        "    ecc_array[i] = 'DIR \"' + permutations[i][0] + '-ECC\"  ECC ' + str(ecc_percent)\n",
        "\n",
        "## create a list of length 'n' to define TOPSTORY and BOTTOMSTORY\n",
        "\n",
        "df_stories = pd.concat([df_storyforces['Story'].drop_duplicates().reset_index(drop=True).to_frame().rename(columns={\"Story\": \"TOPSTORY\"}), df_storyforces['Story'].drop_duplicates().shift(-1).fillna(\"L00\").reset_index(drop=True).to_frame().rename(columns={\"Story\": \"BOTTOMSTORY\"})], axis=1)\n",
        "# df_stories =  pd.concat([df_storyforces['Story'].drop_duplicates().reset_index(drop=True).to_frame().rename(columns={\"Story\": \"TOPSTORY\"}), df_storyforces['Story'].drop_duplicates().reset_index(drop=True).to_frame().rename(columns={\"Story\": \"BOTTOMSTORY\"})], axis=1)\n",
        "\n",
        "story_array = [None] * n\n",
        "for i in range(n):\n",
        "  TOPSTORY = permutations[i][3]\n",
        "  BOTTOMSTORY = df_stories.loc[df_stories['TOPSTORY'] == TOPSTORY, 'BOTTOMSTORY'].iloc[0]\n",
        "  story_array[i] = 'TOPSTORY' + ' \"' + TOPSTORY + '\"    ' + 'BOTTOMSTORY' + ' \"' + BOTTOMSTORY + '\"    '\n",
        "\n",
        "## assign SHEARCOEFF based on TOPSTORY definition\n",
        "shear_array = [None] * n\n",
        "shear_values = [None] * n\n",
        "for i in range(n):\n",
        "  if permutations[i][0] == \"X\":\n",
        "    shear_values[i] = base_shear_coeff_VX.loc[base_shear_coeff_VX['Story'] == permutations[i][3], 'Coeff'].iloc[0].round(4)\n",
        "  else:\n",
        "    shear_values[i] = base_shear_coeff_VY.loc[base_shear_coeff_VY['Story'] == permutations[i][3], 'Coeff'].iloc[0].round(4)\n",
        "\n",
        "# FYI: shear coefficients cannot be negative values in User Coefficient Load Patterns\n",
        "  shear_array[i] = 'SHEARCOEFF ' + str(shear_values[i]) + '  HEIGHTEXPONENT 1'\n",
        "\n",
        "# create final array\n",
        "load_pattern_array2 = [None] * n\n",
        "\n",
        "for i in range(n):\n",
        "  load_pattern_array2[i] = '  SEISMIC ' + pattern_array[i] + '  \"User Coefficient\"    ' + ecc_array[i] + '  ' + story_array[i] + shear_array[i]\n"
      ],
      "metadata": {
        "id": "uahuBHBGKEHc"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_pattern_array = load_pattern_array1 +  load_pattern_array2"
      ],
      "metadata": {
        "id": "3W5FgyXC9gxd"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Generate Load Cases"
      ],
      "metadata": {
        "id": "dbMoIJDOLoG6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loadcase_line1_array = [None] * n\n",
        "loadcase_line2_array = [None] * n\n",
        "load_case_array = [None] * n*2\n",
        "for i in range(n):\n",
        "  loadcase_line1_array[i] = '  LOADCASE ' + pattern_array[i] + '  TYPE  \"Linear Static\"  INITCOND  \"PRESET\"  '\n",
        "  if permutations[i][1] == \"P\":\n",
        "    loadcase_line2_array[i] = '  LOADCASE ' + pattern_array[i] + '  LOADPAT  ' + pattern_array[i] + '  SF  1'\n",
        "  else:\n",
        "    loadcase_line2_array[i] = '  LOADCASE ' + pattern_array[i] + '  LOADPAT  ' + pattern_array[i] + '  SF  -1'\n",
        "\n",
        "\n",
        "for i in range(n*2):\n",
        "  load_case_array[::2] = loadcase_line1_array\n",
        "  load_case_array[1::2] = loadcase_line2_array"
      ],
      "metadata": {
        "id": "V6_Ctdf0Lpu5"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate Utility Load Combinations"
      ],
      "metadata": {
        "id": "ggH0Ghc-EdG_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "utility_combo1 = [];\n",
        "\n",
        "type = '\"Linear Add\"'\n",
        "\n",
        "#permutations required for utility combo 1 capturing positive/negative direction and eccentricity for a given axis (X,Y) and floor level\n",
        "utility_combo1_permutations = generate_permutations(param_axis,param_direction,param_ecc,param_level) #additional param_level to add individual levels for each Fpx load combo\n",
        "fpx_combo_permutations = generate_permutations(param_level)\n",
        "\n",
        "utility_combo1_len = len(utility_combo1_permutations)\n",
        "fpx_combo_len = len(fpx_combo_permutations)\n",
        "\n",
        "#utility load combo1 array defining all the combos we need for utility combo1\n",
        "utility_combo1_array = [None] * utility_combo1_len\n",
        "\n",
        "#define utility combo\n",
        "for i in range(utility_combo1_len):\n",
        "  utility_combo1_array[i] = '\"ELF-EQ' + utility_combo1_permutations[i][0] + '-' + utility_combo1_permutations[i][1] + '-' + utility_combo1_permutations[i][2]  + '-Fpx-' + utility_combo1_permutations[i][3] +'\"'\n",
        "\n",
        "#define combos/cases included in utility combo\n",
        "for i in range(utility_combo1_len):\n",
        "    utility_combo1.append('  COMBO  ' + utility_combo1_array[i] + '  TYPE ' + type)\n",
        "    #Fpx scale factor depending on axis of force (X,Y)\n",
        "    SF = Fpx_SF.iloc[Fpx_SF.index.get_loc(utility_combo1_permutations[i][0]), Fpx_SF.columns.get_loc(utility_combo1_permutations[i][3])]\n",
        "\n",
        "    #apply Fpx only if the floor matches the loop increment\n",
        "    for j in range(fpx_combo_len):\n",
        "      if ((fpx_combo_permutations[j][0] == utility_combo1_permutations[i][3])):\n",
        "        utility_combo1.append( '  COMBO  ' + utility_combo1_array[i] + '  LOADCASE  ' + pattern_array[i] + '  SF ' + str(SF) )\n",
        "      else:\n",
        "        utility_combo1.append( '  COMBO  ' + utility_combo1_array[i] + '  LOADCASE  ' + pattern_array[i] + '  SF 1 ' )\n",
        ""
      ],
      "metadata": {
        "id": "ehuSXs3j0YHn"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #Envelope all eccentricity and direction on a given floor, for both X and Y\n",
        "\n",
        "# utility_combo1 = [];\n",
        "\n",
        "# type = '\"Envelope\"'\n",
        "\n",
        "# #permutations required for utility combo 1 capturing positive/negative direction and eccentricity for a given axis (X,Y) and floor level\n",
        "# utility_combo1_permutations = generate_permutations(param_axis, param_level)\n",
        "# utility_combo1_len = len(utility_combo1_permutations)\n",
        "\n",
        "# #utility load combo1 array defining all the combos we need for utility combo1\n",
        "# utility_combo1_array = [None] * utility_combo1_len\n",
        "\n",
        "# for i in range(utility_combo1_len):\n",
        "#   utility_combo1_array[i] = '\"ELF-EQ' + utility_combo1_permutations[i][0] + '-' + utility_combo1_permutations[i][1]+'\"'\n",
        "\n",
        "# for x in range(utility_combo1_len):\n",
        "#     utility_combo1.append('  COMBO  ' + utility_combo1_array[x] + '  TYPE ' + type)\n",
        "#     for i in range(n):\n",
        "#       if ((permutations[i][0] == utility_combo1_permutations[x][0]) and (permutations[i][3] == utility_combo1_permutations[x][1])):\n",
        "#          utility_combo1.append( '  COMBO  ' + utility_combo1_array[x] + '  LOADCASE  ' + pattern_array[i] + '  SF 1 ')"
      ],
      "metadata": {
        "id": "_OM4R6WSEh-G"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #Linear-Add all Levels while adding Fpx scale factor to single floors\n",
        "\n",
        "# utility_combo2 = [];\n",
        "\n",
        "# type = '\"Linear Add\"'\n",
        "\n",
        "# #permutations required for utility combo 2 capturing Fpx scaling for single floor for each direction (X,Y) with linear add of all floors\n",
        "# utility_combo2_permutations = generate_permutations(param_axis, param_level)\n",
        "# utility_combo2_len = len(utility_combo2_permutations)\n",
        "\n",
        "# #utility load combo2 array defining all the combos we need for utility combo1\n",
        "# utility_combo2_array = [None] * utility_combo2_len\n",
        "\n",
        "# for i in range(utility_combo2_len):\n",
        "#   utility_combo2_array[i] = '\"ELF-EQ' + utility_combo2_permutations[i][0] + '-Fpx-' + utility_combo2_permutations[i][1]+'\"'\n",
        "\n",
        "# #create utility laod combo2 array\n",
        "# for x in range(utility_combo2_len):\n",
        "#     utility_combo2.append('  COMBO  ' + utility_combo2_array[x] + '  TYPE ' + type)\n",
        "\n",
        "#     #Fpx scale factor depending on axis of force (X,Y)\n",
        "#     SF = Fpx_SF.iloc[Fpx_SF.index.get_loc(utility_combo2_permutations[x][0]), Fpx_SF.columns.get_loc(utility_combo2_permutations[x][1])]\n",
        "\n",
        "#     for i in range(utility_combo2_len):\n",
        "\n",
        "#       #apply Fpx only if the floor matches the loop increment\n",
        "#       if ((utility_combo1_permutations[i][0] == utility_combo2_permutations[x][0]) and (utility_combo1_permutations[i][1] == utility_combo2_permutations[x][1])):\n",
        "#          utility_combo2.append( '  COMBO  ' + utility_combo2_array[x] + '  LOADCOMBO  ' + utility_combo1_array[i] + '  SF ' + str(SF) )\n",
        "\n",
        "#       elif (utility_combo1_permutations[i][0] == utility_combo2_permutations[x][0]):\n",
        "#          utility_combo2.append( '  COMBO  ' + utility_combo2_array[x] + '  LOADCOMBO  ' + utility_combo1_array[i] + '  SF 1 ' )\n"
      ],
      "metadata": {
        "id": "aJQXHhVe-Olz"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Envelope by direction (X,Y) for all floors in order to get final\n",
        "\n",
        "utility_combo3 = [];\n",
        "\n",
        "type = '\"Envelope\"'\n",
        "\n",
        "#permutations required for utility combo 2 capturing Fpx scaling for single floor for each direction (X,Y) with linear add of all floors\n",
        "utility_combo3_permutations = generate_permutations(param_axis)\n",
        "utility_combo3_len = len(utility_combo3_permutations)\n",
        "\n",
        "#utility load combo3 array defining all the combos we need for utility combo1\n",
        "utility_combo3_array = [None] * utility_combo3_len\n",
        "\n",
        "for i in range(utility_combo3_len):\n",
        "  utility_combo3_array[i] = '\"ELF-EQ' + utility_combo3_permutations[i][0] +'\"'\n",
        "\n",
        "#create utility laod combo2 array\n",
        "for x in range(utility_combo3_len):\n",
        "  utility_combo3.append('  COMBO  ' + utility_combo3_array[x] + '  TYPE ' + type)\n",
        "\n",
        "  for i in range(utility_combo2_len):\n",
        "\n",
        "    #apply Fpx only if the floor matches the loop increment\n",
        "    if ((utility_combo2_permutations[i][0] == utility_combo3_permutations[x][0])):\n",
        "       utility_combo3.append( '  COMBO  ' + utility_combo3_array[x] + '  LOADCOMBO  ' + utility_combo2_array[i] +'  SF 1 ' )"
      ],
      "metadata": {
        "id": "OKqBj4qVKEmN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "20b9f4ff-0696-4df1-d9ae-956a7461854b"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "can only concatenate str (not \"NoneType\") to str",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-102-2818667cef26>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m#apply Fpx only if the floor matches the loop increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutility_combo2_permutations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mutility_combo3_permutations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m        \u001b[0mutility_combo3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m'  COMBO  '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mutility_combo3_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'  LOADCOMBO  '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mutility_combo2_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'  SF 1 '\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"NoneType\") to str"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "load_combo_array = utility_combo1 + utility_combo2 + utility_combo3"
      ],
      "metadata": {
        "id": "pDYGSfhdJKuP"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Write to a .txt file (temporary)"
      ],
      "metadata": {
        "id": "xku_WsS-XuiA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Insert Load Patterns, Cases, and Combos into .e2k file"
      ],
      "metadata": {
        "id": "xo_FPu8Kn4eB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_and_replace(input_file, output_file, search_text, replacement_lines):\n",
        "    \"\"\"\n",
        "    Replaces the first occurrence of lines starting with `search_text` with `replacement_lines`.\n",
        "\n",
        "    :param input_file: Path to the input text file.\n",
        "    :param output_file: Path to the output text file.\n",
        "    :param search_text: The text to search for at the beginning of a line.\n",
        "    :param replacement_lines: List of replacement lines (without '\\n').\n",
        "    \"\"\"\n",
        "    # Ensure replacement lines end with '\\n'\n",
        "    replacement_lines = [line + \"\\n\" for line in replacement_lines]\n",
        "\n",
        "    # Read the file\n",
        "    with open(input_file, \"r\") as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    # Find the first occurrence index of `search_text`\n",
        "    first_index = next((i for i, line in enumerate(lines) if line.startswith(search_text)), -1)\n",
        "\n",
        "    # Remove all occurrences of `search_text`\n",
        "    filtered_lines = [line for line in lines if not line.startswith(search_text)]\n",
        "\n",
        "    # Insert replacement lines at the position of the first removed occurrence\n",
        "    if first_index != -1:\n",
        "        filtered_lines[first_index:first_index] = replacement_lines  # Insert at first_index\n",
        "\n",
        "    # Write the modified content to a new file (or overwrite the original)\n",
        "    with open(output_file, \"w\") as file:\n",
        "        file.writelines(filtered_lines)\n",
        "\n",
        "    print(f\"File processed successfully. Check {output_file}\")\n"
      ],
      "metadata": {
        "id": "XhIOu0U8P_6y"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define file paths\n",
        "input_file = e2k_file  # Replace with your actual file name\n",
        "output_file = \"ELF-\"+e2k_file  # Output file name\n",
        "\n",
        "# Replace load patterns pt. 1\n",
        "find_and_replace(input_file, \"temp1\"+output_file, '  LOADPATTERN \"ELF-', load_pattern_array1)\n",
        "\n",
        "# Replace load patterns pt. 2\n",
        "find_and_replace(\"temp1\"+output_file, \"temp2\"+output_file, '  SEISMIC \"ELF-', load_pattern_array2)\n",
        "\n",
        "# Replace load cases\n",
        "find_and_replace(\"temp2\"+output_file, \"temp3\"+output_file, '  LOADCASE \"ELF-', load_case_array)\n",
        "\n",
        "# Replace load combos\n",
        "find_and_replace(\"temp3\"+output_file, output_file, '  COMBO \"ELF-', load_combo_array)\n"
      ],
      "metadata": {
        "id": "gvYdcBcgQmRU",
        "outputId": "ba649dd3-ba23-46f9-f87f-6f2ee7fbcbfb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File processed successfully. Check temp1ELF-RSFH_PODIUM_V11.2.4.e2k\n",
            "File processed successfully. Check temp2ELF-RSFH_PODIUM_V11.2.4.e2k\n",
            "File processed successfully. Check temp3ELF-RSFH_PODIUM_V11.2.4.e2k\n",
            "File processed successfully. Check ELF-RSFH_PODIUM_V11.2.4.e2k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# with open(\"testloads2.txt\", \"w\") as file:\n",
        "#     for item in load_pattern_array:\n",
        "#         file.write(item + '\\n')  # Write each item on a new line\n",
        "\n",
        "# with open(\"testloads2.txt\", \"a\") as file:\n",
        "#     for item in load_case_array:\n",
        "#         file.write(item + '\\n')  # Write each item on a new line\n",
        "\n",
        "# with open(\"testloads2.txt\", \"a\") as file:\n",
        "#     for item in load_combo_array:\n",
        "#         file.write(item + '\\n')  # Write each item on a new line\n"
      ],
      "metadata": {
        "id": "drat8y5xX7zj"
      },
      "execution_count": 27,
      "outputs": []
    }
  ]
}